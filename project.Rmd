---
title: "project"
author: ""
date: "2025-11-25"
output: html_document
---

The dataset used in this project corresponds to the supplementary file **MOESM2 (ESM)** from the publication by Fan et al. (2018). It contains the raw GC-TOF-MS metabolomics data for 120 urine samples\
from healthy adults (60 males and 60 females), enabling independent preprocessing, exploratory analysis, feature selection, and classification.

# Import Library

```{r}
library(readxl)
library(tidyverse)
library(ggplot2)
library(ellipse)
library(caret)
library(pROC)
library(pls)
library(DescTools)
library(dplyr)
library(mixOmics)
```

# Import dataset

```{r}
raw_df <- read_excel("41598_2018_29592_MOESM2_ESM.xlsx")
```

```{r}
sex <- unlist(raw_df[3, -1])
sex <- as.factor(sex)

df <- read_excel("41598_2018_29592_MOESM2_ESM.xlsx", skip = 6)

glimpse(df)
```

# Cleaning and Data Transformation

```{r}
# organize names
# first df line has de colnames
colnames(df) <- df[1, ]

df <- df[-1, ]

# convert to numeric
for (i in 17:ncol(df)) {  # first 16 columns = metadata
  df[[i]] <- as.numeric(df[[i]])
}

X <- df[, 17:ncol(df)] 

Y <- sex

colnames(X) <- paste0("S", seq_len(ncol(X)))

# number of metabolites and samples
dim(X)

```

It matches with the article 120 samples (60 males + 60 females)

# Summary statistics

```{r}
summary(X)
```

```{r}
# Count total zero values
sum(X == 0, na.rm = TRUE)
```

```{r}
# Missing values check
sum(is.na(X))
```

# Is it the data Gaussian Distributed?

```{r}
par(mfrow=c(1,2))
hist(as.numeric(X[1,]), main="Raw Distribution", xlab="Intensity")
qqnorm(as.numeric(X[1,]), main="QQ Plot Raw")
qqline(as.numeric(X[1,]))
par(mfrow=c(1,1))
```

# Histogram inspection

To assess distributional properties, histogram inspection was performed. Raw metabolite intensities showed pronounced right-skewness, supporting the need for a log-transformation to improve normality and stabilize variance prior to multivariate analysis.

```{r}
feat1 <- as.numeric(X[[1]])
feat2 <- as.numeric(X[[2]])

par(mfrow = c(2,2))

# Raw intensity distributions
hist(feat1, main = "Raw Intensities - Feature 1", xlab = "", col = "lightgray")
hist(feat2, main = "Raw Intensities - Feature 2", xlab = "", col = "lightgray")

# After log10 transformation
hist(log10(feat1 + 1), main = "Log10 - Feature 1", xlab = "", col = "lightgray")
hist(log10(feat2 + 1), main = "Log10 - Feature 2", xlab = "", col = "lightgray")

par(mfrow = c(1,1))
```

The raw intensity histograms show strong right-skewness with extreme values. After log10 transformation, the distributions become more symmetric and less heteroscedastic, supporting the use of log-transformed and autoscaled data for PCA and PLS-DA.

# Non linear

```{r}
# Convert to standard data frame to avoid tibble recycling issues
X_nozero <- as.data.frame(X)

for(i in 1:nrow(X_nozero)){
  row_vals <- as.numeric(X_nozero[i, ])  # convert row to numeric vector

  # Safeguard: if the row is all zeros (rare but possible)
  if(all(row_vals == 0)){
    row_vals[row_vals == 0] <- 1  # placeholder before log10
  } else {
    min_val <- min(row_vals[row_vals > 0], na.rm = TRUE)
    row_vals[row_vals == 0] <- min_val / 2
  }

  X_nozero[i, ] <- row_vals  # assign back properly
}
```

# PCA

A preliminary variance-based feature filtering step (top 20% most variable metabolites) was evaluated as an unsupervised method for noise reduction and dimensionality control. However, this procedure resulted in the removal of several metabolites previously identified as statistically significant in the univariate analysis, consequently reducing the number of biologically relevant features and weakening the discrimination between sexes in downstream multivariate models. Therefore, variance filtering was not retained in the final workflow to preserve subtle yet meaningful metabolic differences.

The matrix was transposed so that samples correspond to rows and metabolites to columns, which is the correct structure required for multivariate analyses such as PCA and PLS-DA, where each row must represent an independent observation:

-   With \<- scale(t(X_log)).

```{r}
# Log10 transformation
X_log <- log10(X_nozero)

# Scaling for PCA (samples as rows)
X_scaled <- scale(t(X_log))

# PCA
pca <- prcomp(X_scaled, center = TRUE, scale. = FALSE)
summary(pca)

```

-   Summary statistics show very different scales and non-normal distributions

-   A few zero values detected → replaced with half of minimum value\
    → required for log10 transformation

-   Applied log10(x) to reduce skewness and stabilize variance

-   Autoscaling (mean-center + unit variance) to make metabolites comparable

```{r}
sex_row <- as.character(raw_df[3, ])

sample_names_raw <- sex_row[sex_row %in% c("Male", "Female")]

sample_cols <- colnames(X)

sex <- factor(sample_names_raw[1:length(sample_cols)])

length(sex)
table(sex)

all(!is.na(sex))
identical(length(sex), nrow(pca$x))

```

```{r}
pca_scores <- as.data.frame(pca$x[, 1:2])


center <- colMeans(pca_scores)
cov_mat <- cov(pca_scores)

distances <- mahalanobis(pca_scores, center, cov_mat)

# Cutoff (chi with p=0.95 and 2 df)
cutoff <- qchisq(0.95, df = 2)

# plot with condidese matrix
plot(pca$x[,1], pca$x[,2], 
     pch = 19, 
     col = ifelse(distances > cutoff, "red", "black"), # Outliers a vermelho
     xlab = "PC1", ylab = "PC2", 
     main = "PCA Outlier Detection (95% CI)")

lines(ellipse(cov_mat, centre = center, level = 0.95), col="blue", lty=2)

text(pca$x[,1], pca$x[,2], 
     labels = ifelse(distances > cutoff, rownames(pca$x), ""), 
     pos = 3, cex = 0.7)

# Identify outliers
outliers <- which(distances > cutoff)
print(paste("Outliers detected:", length(outliers)))
```

We detected 9 outliers, but they weren't removed because:

Outliers reflect **real biological variability** within the healthy population.\
Removing them could introduce **bias**, especially if outliers are unevenly distributed between sexes.\
Furthermore, the original study **did not exclude any samples** all **120 subjects** were analyzed in full.

# PCA after log transformation

```{r}
score_df <- data.frame(
  PC1 = pca$x[,1],
  PC2 = pca$x[,2],
  Sex = sex
)

ggplot(score_df, aes(PC1, PC2, color = Sex)) +
  geom_point(size = 3) +
  theme_classic() +
  ggtitle("PCA After Log10 Transform + Scaling")


```

```{r}
# Scree plot (PCA Variance Explained)
variance <- pca$sdev^2 / sum(pca$sdev^2)

plot(variance[1:10], type="b", pch=19,
     xlab="PC", ylab="Proportion of Variance",
     main="Scree Plot - PCA")

```

-   Score plot shows a trend of separation between Male and Female

-   Some possible outliers appear (next step: detection)

-   Scree Plot indicates PC1+PC2 explain \~20–30% variance → normal for metabolomics

# Split Test/Training

We split the data into training and test sets (70/30) and perform univariate t-tests on the training set only. FDR correction is applied to identify metabolites significantly different between sexes.

```{r}
set.seed(123)

train_index <- createDataPartition(sex, p = 0.7, list = FALSE)

X_train <- X_scaled[train_index, ]
X_test  <- X_scaled[-train_index, ]

X_train <- as.data.frame(X_train)
X_test  <- as.data.frame(X_test)

y_train <- sex[train_index]
y_test  <- sex[-train_index]

pvals <- apply(X_train, 2, function(x) t.test(x ~ y_train)$p.value)
pvals_fdr <- p.adjust(pvals, method = "fdr")

head(sort(pvals_fdr))
```

Several metabolites show significant sex differences (FDR \< 0.05). These will be considered as candidates for biomarker selection in the supervised modeling step.

# Initials PLS-DA

An initial PLS-DA model with 10 components was trained on the training set to evaluate whether the metabolomic profiles discriminate between sexes.

```{r}
#Initial PLS-DA model
pls_initial <- plsda(X_train, y_train, ncomp = 10)

plotIndiv(pls_initial, comp = c(1,2),
          group = y_train, legend = TRUE,
          title = "Initial PLS-DA (Training Set)")
```

The PLS-DA score plot shows a clear separation between males and females along the first two latent variables, indicating strong sex-related differences in urinary metabolomic profiles.

# Internal Validation: 5-Fold CV + AUCROC

A 5-fold cross-validation was used on the training set to determine the optimal number of latent variables (LVs) for the PLS-DA model, using AUC as the performance metric.

```{r}

set.seed(123)

folds <- createFolds(y_train, k = 5, returnTrain = TRUE)
auc_results <- data.frame(LV = integer(), AUC = numeric())

for (lv in 1:5) {
  auc_fold <- c()
  
  for (f in folds) {
    model <- plsda(X_train[f,], y_train[f], ncomp = lv)
    pred <- predict(model, X_train[-f,])$predict[,1,lv]
    roc_obj <- roc(y_train[-f], pred)
    auc_fold <- c(auc_fold, auc(roc_obj))
  }
  
  auc_results <- rbind(auc_results,
                       data.frame(LV = lv,
                                  AUC = mean(auc_fold)))
}

auc_results

```

LV = 3 showed the highest mean AUC, and was therefore selected as the optimal number of components for the final PLS-DA model.

# Univariate Analysis on Training set (Male vs Female)

Univariate Welch t-tests were applied to each metabolite in the training set, followed by FDR correction. Mean differences (Male – Female) were calculated to determine the direction of change.

```{r}
# Compute raw p-values using Welch t-test for each metabolite
pvals <- apply(X_train, 2, function(x) t.test(x ~ y_train)$p.value)

# FDR correction (Benjamini-Hochberg)
pvals_fdr <- p.adjust(pvals, method = "fdr")


fc <- apply(X_train, 2, function(x) mean(x[y_train == "Male"]) -
                               mean(x[y_train == "Female"]))


uni_results <- data.frame(
  Metabolite = colnames(X_train),
  p_value = pvals,
  p_FDR = pvals_fdr,
  mean_diff = fc
)


uni_results <- uni_results[order(uni_results$p_FDR), ]
significant <- uni_results[uni_results$p_FDR < 0.05, ]
significant

```

Several metabolites showed significant sex differences (FDR \< 0.05). These features represent potential biomarkers and will be further evaluated in the supervised model.

# Volcano Plot - Univariate Analysis

A volcano plot was generated to visualize effect size (mean difference) against statistical significance (FDR-corrected p-values).

```{r}
library(ggplot2)

volcano <- uni_results
volcano$logP <- -log10(volcano$p_FDR)

ggplot(volcano, aes(x = mean_diff, y = logP)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = -log10(0.05), col = "red", lty = 2) +
  theme_classic() +
  xlab("Mean Difference (Male – Female)") +
  ylab("-log10(FDR)") +
  ggtitle("Volcano Plot — Univariate Analysis (Training Set)")

```

Univariate analysis performed on the training set identified 9 metabolites with significant sex-related differences after FDR correction (p_FDR \< 0.05). Six metabolites (V22, V399, V84, V51, V291, V57) showed higher concentrations in females, while three metabolites (V10, V113, V250) were higher in males. The strongest discriminators were V22 and V399 (p_FDR \< 0.005).

```{r}
colnames(X_train) <- paste0("X", 1:ncol(X_train))
colnames(X_test)  <- paste0("X", 1:ncol(X_test))

y_train <- as.factor(y_train)
y_test  <- as.factor(y_test)
```

```{r}
set.seed(30)

perf_res <- perf(pls_initial,
                 validation = "Mfold",
                 folds = 5,
                 nrepeat = 5,
                 progressBar = FALSE)

plot(perf_res, sd = TRUE)

```

Calculate the optimal number of components, using other metrics, like BER. This shows that increasing the number of components doesnt always decrease the error.

As an additional exploratory validation, the perf() method from mixOmics was applied. Although BER suggested 4 components, this criterion is less appropriate for binary classification than AUC. Therefore, AUC-based tuning remained the primary selection method.

```{r}
optimal_ncomp <- which.min(perf_res$error.rate$BER)
optimal_ncomp
```

```{r}
optimal_ncomp <-3
pls_final <- plsda(X_train, y_train, ncomp = optimal_ncomp)

plotIndiv(pls_final, comp = c(1,2),
          group = y_train, legend = TRUE,
          title = "Final PLS-DA (Training Set) — 3 components")
```

We selected n = 3 components because they maximised the AUC during cross-validation while avoiding unnecessary model complexity. Although BER suggested 4 components, the improvement was marginal and adding extra components risks overfitting, especially in a two-class dataset.

```{r}
pred_test <- predict(pls_final, X_test)
pred_class <- pred_test$class$max.dist[, optimal_ncomp]

table(True = y_test, Predicted = pred_class)
mean(pred_class == y_test)
```

```{r}
test_variates <- pred_test$variates

test_df <- data.frame(
  Comp1 = test_variates[,1],
  Comp2 = if (optimal_ncomp >= 2) test_variates[,2] else rep(0, nrow(test_variates)),
  Class = y_test
)

ggplot(test_df, aes(Comp1, Comp2, color = Class)) +
  geom_point(size = 3) +
  theme_minimal() +
  ggtitle("PLS-DA Test Set Scores")
```

The final PLS-DA model does not show a visibly stronger separation because the main class structure was already captured by the first two components in the initial model. Tuning improves model stability and classification performance, but these gains occur mostly beyond component 2, which is why the 2D score plot appears similar.

Next - VP scores
